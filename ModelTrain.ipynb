{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5861cf2d-3662-4277-80d7-047d27fd26b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9ce815-c854-430e-940b-81ab3e992557",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sweetviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f285dfa1-58d4-4944-b3b2-56ec583da96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandasTools or pip install \"Pandas<2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b9e041-4a3c-4f78-802b-e71470f9c179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                 # for data manipulation\n",
    "import seaborn as sns               # for data visualization\n",
    "import matplotlib.pyplot as plt     # for data visualization\n",
    "import numpy as np                  # for numerical operations\n",
    "import sweetviz as sv               # for fast exploratory data analysis (eda)\n",
    "\n",
    "from rdkit import Chem              # for calculating cheminformatics properties of molecules\n",
    "from rdkit.Chem import Descriptors  # for determining chemical descriptors\n",
    "from rdkit.Chem import Crippen      # for calculating logP (cLogP)\n",
    "from rdkit.Chem import PandasTools  # for displaying molecules\n",
    "PandasTools.RenderImagesInAllDataFrames(images=True) # Ensures molecules are rendered in the notebook\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler            # for scaling the data\n",
    "from sklearn.model_selection import train_test_split        # for splitting the data into training and testing sets\n",
    "from sklearn.model_selection import cross_val_score, KFold  # for K-fold cross-validation\n",
    "from sklearn.linear_model import LinearRegression           # for creating a linear regression model\n",
    "from sklearn.ensemble import RandomForestRegressor          # for creating a random forest regression model\n",
    "from sklearn.dummy import DummyRegressor                    # for creating a base regressor to compare the model with\n",
    "from sklearn.metrics import mean_squared_error, r2_score    # for evaluating the model\n",
    "from sklearn.pipeline import make_pipeline                  # for building operational pipelines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d2d720-a32f-4c82-8999-1070bd24c05e",
   "metadata": {},
   "source": [
    "# Splitting the Data Into Training and Testing Sets\n",
    "\n",
    "The training set is used to train the model, and the testing set is used to evaluate the model's performance. This process allows you to test the model's accuracy on unseen data and ensures that the model can generalize well to new data.\n",
    "\n",
    "To create our training and testing data sets, we will use the ``train_test_split`` function from the ``sklearn.model_selection`` module to split the data. \n",
    "\n",
    "\n",
    "\n",
    "``x`` generally denotes the input variables (the data the model will use to make predictions)\n",
    "``y`` is often used for target variable (what we are trying to predict)\n",
    "``test_size`` is used to assign the percentage of the data set aside for the testing set\n",
    "``random_state`` controls the random number generator used to shuffle the data before splitting it. This is especially useful if you want to compare the performance of multiple models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa33d6d9-f9ca-49fe-8404-baaa7e3d1d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"solubility-molecule-list.csv\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea78b67-fca9-4208-9e69-a16962726134",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mol'] = df['smiles'].apply(Chem.MolFromSmiles)\n",
    "df['mol_weight'] =df['mol'].apply(Descriptors.MolWt)\n",
    "df['rot_bonds'] =df['mol'].apply(Chem.rdMolDescriptors.CalcNumRotatableBonds)\n",
    "df['clogP'] =df['mol'].apply(Chem.Crippen.MolLogP)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff3721a-a3b0-495b-ae99-4a02ac52fe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the feature matrix (X), feature vector (x), and the target vector (y)\n",
    "X = df.drop(columns=['logS'])\n",
    "x = X[\"clogP\"]\n",
    "y = df['logS']\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=123, shuffle=True)\n",
    "\n",
    "# Reshape the data into 2D arrays of shape (n_samples, 1)\n",
    "# (if working with only one input feature)\n",
    "x_train = x_train.values.reshape(-1,1)\n",
    "x_test = x_test.values.reshape(-1,1)\n",
    "y_train = y_train.values.reshape(-1,1)\n",
    "y_test = y_test.values.reshape(-1,1)\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346649db-ccde-47c9-b607-20d2fed4c91d",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Feature engineering is the process of transforming the raw data into a format that is suitable for machine learning models. It involves creating new features, selecting the most important features, and transforming the existing features in order to improve the model's performance.\n",
    "\n",
    "After splitting our data, we need to scale our train and test features. Scaling is a crucial step in the data preprocessing pipeline as it ensures that all features have the same scale, since many machine learning models are sensitive to the scale of the input features. We will use the StandardScaler from the ``sklearn.preprocessing`` module to scale our features. ``StandardScaler`` transforms the data in such a manner that it has mean value of 0 and a standard deviation value of 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aeef88-4772-4bfd-b40b-bde42f60fe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the standard scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training feature vector x_train\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "\n",
    "# Transform the test feature vector x_test\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# Make sure the training data is scaled correctly\n",
    "print(f\" Training feature mean: {x_train_scaled.mean():.5f}\")\n",
    "print(f\" Training feature standard deviation: {x_train_scaled.std():.5f}\\n\")\n",
    "\n",
    "# Print the scaler statistics on the test data\n",
    "print(f\" Testing feature mean: {x_test_scaled.mean():.5f}\")\n",
    "print(f\" Testing feature standard deviation: {x_test_scaled.std():.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854de055-fa00-4105-a29e-f72813b6e5a3",
   "metadata": {},
   "source": [
    "## Building and Training a Simple Linear Regression Model\n",
    "\n",
    "To evaluate the performance of our model, we can first create a dummy \"model\" using the DummyRegressor class from the ``sklearn.dummy`` module. \n",
    "\n",
    "The ``fit``  method is used to train the model on the training data. Once the model is trained, we can use the predict method to make predictions on the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8912085c-0b25-4bda-bf4d-d2cac3c84030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dummy model using the mean value of the target property\n",
    "dummy_model = DummyRegressor(strategy=\"mean\")\n",
    "\n",
    "# Fit the model to the training data\n",
    "dummy_model.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred_dummy = dummy_model.predict(x_test_scaled)\n",
    "\n",
    "# Calculate the performance metrics and store them in a DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"Coefficients\": [np.array(dummy_model.constant_)],   # the regression coefficient\n",
    "    \"MSE\": mean_squared_error(y_test, y_pred_dummy),     # the mean squared error\n",
    "    \"R2\": r2_score(y_test, y_pred_dummy)                 # the coefficient of determination\n",
    "}, index=[\"Dummy\"])\n",
    "                            \n",
    "\n",
    "# Set the formatting style\n",
    "results.style.format(\n",
    "    {\n",
    "        \"MSE\": \"{:.3f}\",\n",
    "        \"R2\": \"{:.2f}\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205c8b78-304c-4123-8d6c-f0d53ce3e4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple linear regression model\n",
    "simple_reg_model = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "simple_reg_model.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_simple = simple_reg_model.predict(x_test_scaled)\n",
    "\n",
    "# Calculate the performance metrics\n",
    "simple_model_results = pd.DataFrame({\n",
    "    \"Coefficients\": [np.array(simple_reg_model.coef_)],   # the regression coefficient\n",
    "    \"MSE\": mean_squared_error(y_test, y_pred_simple),     # the mean squared error\n",
    "    \"R2\": r2_score(y_test, y_pred_simple)                 # the coefficient of determination\n",
    "}, index=[\"Simple-Linear-Regression\"])\n",
    "\n",
    "# Store the results into results DataFrame\n",
    "results = pd.concat([results, simple_model_results])\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8a0bda-2acb-471c-aa6a-af38a919e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot object \n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "# Plot the test data\n",
    "ax.scatter(x_test_scaled, y_test, color='blue', label='Test Data')\n",
    "\n",
    "# Plot the simple linear regression model\n",
    "ax.plot(x_test_scaled, y_pred_simple, color='red', label='Simple Linear Regression')\n",
    "\n",
    "# Plot the baseline model\n",
    "ax.plot(x_test_scaled, y_pred_dummy, \"g--\", label=\"Dummy\")\n",
    "\n",
    "# Create the legends\n",
    "fig.legend(facecolor='white')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
